{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from random import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split(arr, ratio):\n",
    "    return train_test_split(arr, test_size=ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/test split for Median dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forearm/HM/162\n",
      "\t(1) vset: 54, tset: 108, Sum: 162\n",
      "\t(2) vset: 54, tset: 108, Sum: 162\n",
      "\t(3) vset: 54, tset: 108, Sum: 162\n",
      "forearm/SN/191\n",
      "\t(1) vset: 64, tset: 127, Sum: 191\n",
      "\t(2) vset: 64, tset: 127, Sum: 191\n",
      "\t(3) vset: 63, tset: 128, Sum: 191\n",
      "wrist/HM/641\n",
      "\t(1) vset: 214, tset: 427, Sum: 641\n",
      "\t(2) vset: 214, tset: 427, Sum: 641\n",
      "\t(3) vset: 213, tset: 428, Sum: 641\n",
      "wrist/SN/311\n",
      "\t(1) vset: 104, tset: 207, Sum: 311\n",
      "\t(2) vset: 104, tset: 207, Sum: 311\n",
      "\t(3) vset: 103, tset: 208, Sum: 311\n"
     ]
    }
   ],
   "source": [
    "samples = {\n",
    "    \"forearm\" : {\n",
    "        \"HM\" : {\n",
    "            \"str\" : 641,\n",
    "            \"end\" : 802,\n",
    "            \"image\" : \"/home/dongik/datasets/backup-median/newset/forearm_train/forearm_HM70A\",\n",
    "            \"mask\" : \"/home/dongik/datasets/backup-median/newset/forearm_target/forearm_HM70A\"\n",
    "        },\n",
    "        \"SN\" : {\n",
    "            \"str\" : 1114,\n",
    "            \"end\" : 1304,\n",
    "            \"image\" : \"/home/dongik/datasets/backup-median/newset/forearm_train/forearm_miniSONO\",\n",
    "            \"mask\" : \"/home/dongik/datasets/backup-median/newset/forearm_target/forearm_miniSONO\"\n",
    "        }\n",
    "    },\n",
    "    \"wrist\" : {\n",
    "        \"HM\" : {\n",
    "            \"str\" : 0,\n",
    "            \"end\" : 640,\n",
    "            \"image\" : \"/home/dongik/datasets/backup-median/newset/wrist_train/wrist_HM70A\",\n",
    "            \"mask\" : \"/home/dongik/datasets/backup-median/newset/wrist_target/wrist_HM70A\"\n",
    "        },\n",
    "        \"SN\" : {\n",
    "            \"str\" : 803,\n",
    "            \"end\" : 1113,\n",
    "            \"image\" : \"/home/dongik/datasets/backup-median/newset/wrist_train/wrist_miniSONO\",\n",
    "            \"mask\" : \"/home/dongik/datasets/backup-median/newset/wrist_target/wrist_miniSONO\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "Kfold = {\n",
    "    \"k\" : 3,\n",
    "    \"dataset\" : {\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "assert( Kfold['k'] > 1 )\n",
    "\n",
    "for r, v in samples.items():\n",
    "    for m, lst in v.items():\n",
    "        LEN = lst['end'] - lst['str'] + 1\n",
    "        print(f\"{r}/{m}/{LEN}\")\n",
    "        \n",
    "        Arr = np.array([i + lst['str'] for i in range(LEN)])\n",
    "        \n",
    "        arr, valid = Arr, set(Arr.tolist())\n",
    "        for i in range(Kfold['k'] - 1):\n",
    "            arr, Kfold['dataset'][f'{i}'] = split(arr, 1/(Kfold['k'] - i))\n",
    "            if i == Kfold['k'] - 2:\n",
    "                Kfold['dataset'][f'{i+1}'] = arr\n",
    "            valid -= set(arr.tolist())\n",
    "\n",
    "        assert(len(valid) > 0)\n",
    "\n",
    "        for i in range(Kfold['k']):\n",
    "            vset = Kfold['dataset'][f'{i}'].tolist()\n",
    "            tset = list(set(Arr.tolist()) - set(vset))\n",
    "\n",
    "            print(f\"\\t({i+1}) vset: {len(vset)}, tset: {len(tset)}, Sum: {len(vset) + len(tset)}\")\n",
    "\n",
    "            if not os.path.exists(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}\"):\n",
    "                os.makedirs(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}\")\n",
    "  \n",
    "            with open(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}/val.txt\", 'w') as f:\n",
    "                f.write('\\n'.join(str(l) for l in vset))\n",
    "            \n",
    "            with open(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}/train.txt\", 'w') as f:\n",
    "                f.write('\\n'.join(str(l) for l in tset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/home/dongik/datasets/median\"\n",
    "\n",
    "for r, v in samples.items():\n",
    "    for m, lst in v.items():\n",
    "\n",
    "        for fname in os.listdir(lst['image']):\n",
    "            ftype = fname.split('.')[-1]\n",
    "            id = int(fname.split('.')[0])\n",
    "\n",
    "            if id < lst['str'] or id > lst['end']:\n",
    "                raise Exception\n",
    "\n",
    "            shutil.copy(\n",
    "                src=os.path.join(\n",
    "                    lst['image'],\n",
    "                    fname\n",
    "                ),\n",
    "                dst=os.path.join(\n",
    "                    prefix,\n",
    "                    r,\n",
    "                    m,\n",
    "                    f\"median ({id}).{ftype}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for fname in os.listdir(lst['mask']):\n",
    "            ftype = fname.split('.')[-1]\n",
    "            id = int(fname.split('.')[0])\n",
    "\n",
    "            if id < lst['str'] or id > lst['end']:\n",
    "                raise Exception\n",
    "\n",
    "            shutil.copy(\n",
    "                src=os.path.join(\n",
    "                    lst['mask'],\n",
    "                    fname\n",
    "                ),\n",
    "                dst=os.path.join(\n",
    "                    prefix,\n",
    "                    r,\n",
    "                    m,\n",
    "                    f\"median ({id})_mask.{ftype}\"\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/val split for peroneal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/home/dongik/datasets/_peroneal/UN/\"\n",
    "dst = \"/home/dongik/datasets/peroneal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "des = {}\n",
    "for f in sorted(os.listdir(os.path.join(prefix, 'Images'))):\n",
    "    format = f.split('.')[-1]\n",
    "    fname = f.split('.')[0].split('_')\n",
    "\n",
    "    r = fname[0]\n",
    "    id = fname[1]\n",
    "\n",
    "    plural = len(fname) > 2\n",
    "    if plural:\n",
    "        idf = f'{id}_{fname[-1]}'\n",
    "    else:\n",
    "        idf = f'{id}'\n",
    "\n",
    "    if r not in des.keys():\n",
    "        des[r] = {\n",
    "            idf : 1\n",
    "        }\n",
    "    else:\n",
    "        if idf not in des[r].keys():\n",
    "            des[r][idf] = 1\n",
    "        else:\n",
    "            raise Exception\n",
    "    \n",
    "    if not os.path.exists(os.path.join(dst, r, 'UN')):\n",
    "        os.makedirs(os.path.join(dst, r, 'UN'))\n",
    "        os.makedirs(os.path.join(dst, 'splits', r, 'UN'))\n",
    "    \n",
    "    if len(fname) > 2:\n",
    "        fn = f'peroneal ({id}_{fname[-1]}).{format}'\n",
    "    else:\n",
    "        fn = f'peroneal ({id}).{format}'\n",
    "\n",
    "    shutil.copy(\n",
    "        src=os.path.join(\n",
    "            prefix,\n",
    "            'Images',\n",
    "            f\n",
    "        ),\n",
    "        dst=os.path.join(\n",
    "            dst,\n",
    "            r,\n",
    "            'UN',\n",
    "            fn\n",
    "        )\n",
    "    )\n",
    "\n",
    "for f in sorted(os.listdir(os.path.join(prefix, 'Masks'))):\n",
    "    format = f.split('.')[-1]\n",
    "    fname = f.split('.')[0].split('_')\n",
    "\n",
    "    r = fname[0]\n",
    "    id = fname[1]\n",
    "    \n",
    "    plural = len(fname) > 3\n",
    "    if plural:\n",
    "        mn = f'peroneal ({id}_{fname[-2]})_mask.{format}'\n",
    "    else:\n",
    "        mn = f'peroneal ({id})_mask.{format}'\n",
    "\n",
    "    shutil.copy(\n",
    "        src=os.path.join(\n",
    "            prefix,\n",
    "            'Masks',\n",
    "            f\n",
    "        ),\n",
    "        dst=os.path.join(\n",
    "            dst,\n",
    "            r,\n",
    "            'UN',\n",
    "            mn\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN+10 is too small, 1\n",
      "FN+11 is too small, 4\n",
      "FN+12 is too small, 1\n",
      "FN+13 is too small, 1\n",
      "FN+15 is too small, 1\n",
      "FN+7 is too small, 4\n",
      "FN+9 is too small, 3\n",
      "FN-1 is too small, 4\n",
      "POP+1 is too small, 2\n",
      "POP+2 is too small, 4\n",
      "POP+3 is too small, 1\n",
      "POP+5 is too small, 2\n",
      "total: 490\n"
     ]
    }
   ],
   "source": [
    "Kfold = {\n",
    "    \"k\" : 5,\n",
    "    \"dataset\" : {\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "assert( Kfold['k'] > 1 )\n",
    "\n",
    "s = 0\n",
    "for r, v in des.items():\n",
    "    \n",
    "    Arr = np.array(list(v.keys()))\n",
    "    s += len(Arr)\n",
    "\n",
    "    if len(Arr) / Kfold['k'] < 1.0:\n",
    "        print(f'{r} is too small, {len(Arr)}')\n",
    "        continue\n",
    "    \n",
    "    arr, valid = Arr, set(Arr.tolist())\n",
    "    for i in range(Kfold['k'] - 1):\n",
    "        arr, Kfold['dataset'][f'{i}'] = split(arr, 1/(Kfold['k'] - i))\n",
    "        if i == Kfold['k'] - 2:\n",
    "            Kfold['dataset'][f'{i+1}'] = arr\n",
    "        valid -= set(arr.tolist())\n",
    "\n",
    "    assert(len(valid) > 0)\n",
    "\n",
    "    for i in range(Kfold['k']):\n",
    "        vset = Kfold['dataset'][f'{i}'].tolist()\n",
    "        tset = list(set(Arr.tolist()) - set(vset))\n",
    "\n",
    "        #print(f\"\\t({i+1}) vset: {len(vset)}, tset: {len(tset)}, Sum: {len(vset) + len(tset)}\")\n",
    "\n",
    "        if not os.path.exists(f\"/home/dongik/datasets/peroneal/splits/{r}/UN/v{Kfold['k']}/{i}\"):\n",
    "            os.makedirs(f\"/home/dongik/datasets/peroneal/splits/{r}/UN/v{Kfold['k']}/{i}\")\n",
    "\n",
    "        with open(f\"/home/dongik/datasets/peroneal/splits/{r}/UN/v{Kfold['k']}/{i}/val.txt\", 'w') as f:\n",
    "            f.write('\\n'.join(str(l) for l in vset))\n",
    "        \n",
    "        with open(f\"/home/dongik/datasets/peroneal/splits/{r}/UN/v{Kfold['k']}/{i}/train.txt\", 'w') as f:\n",
    "            f.write('\\n'.join(str(l) for l in tset))\n",
    "            \n",
    "print(f'total: {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FH : 91\n",
      "FN+10 : 1\n",
      "FN+11 : 4\n",
      "FN+12 : 1\n",
      "FN+13 : 1\n",
      "FN+15 : 1\n",
      "FN+1 : 77\n",
      "FN+2 : 58\n",
      "FN+3 : 49\n",
      "FN+4 : 29\n",
      "FN+5 : 16\n",
      "FN+6 : 6\n",
      "FN+7 : 4\n",
      "FN+8 : 8\n",
      "FN+9 : 3\n",
      "FN-1 : 4\n",
      "FN : 106\n",
      "POP+1 : 2\n",
      "POP+2 : 4\n",
      "POP+3 : 1\n",
      "POP+5 : 2\n",
      "POP : 22\n",
      "total: 490\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for k, v in des.items():\n",
    "    s += v['cnt']\n",
    "    print(k, ':', v['cnt'])\n",
    "    for id, cnt in v['id'].items():\n",
    "        if cnt > 1:\n",
    "            #print(id, ':', cnt)\n",
    "            pass\n",
    "\n",
    "print('total:', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, valid = Arr, set(Arr.tolist())\n",
    "for i in range(Kfold['k'] - 1):\n",
    "    arr, Kfold['dataset'][f'{i}'] = split(arr, 1/(Kfold['k'] - i))\n",
    "    if i == Kfold['k'] - 2:\n",
    "        Kfold['dataset'][f'{i+1}'] = arr\n",
    "    valid -= set(arr.tolist())\n",
    "\n",
    "assert(len(valid) > 0)\n",
    "\n",
    "for i in range(Kfold['k']):\n",
    "    vset = Kfold['dataset'][f'{i}'].tolist()\n",
    "    tset = list(set(Arr.tolist()) - set(vset))\n",
    "\n",
    "    print(f\"\\t({i+1}) vset: {len(vset)}, tset: {len(tset)}, Sum: {len(vset) + len(tset)}\")\n",
    "\n",
    "    if not os.path.exists(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}\"):\n",
    "        os.makedirs(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}\")\n",
    "\n",
    "    with open(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}/val.txt\", 'w') as f:\n",
    "        f.write('\\n'.join(str(l) for l in vset))\n",
    "    \n",
    "    with open(f\"/home/dongik/datasets/median/splits/{r}/{m}/v{Kfold['k']}/{i}/train.txt\", 'w') as f:\n",
    "        f.write('\\n'.join(str(l) for l in tset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train/test split for BUSI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - v: 110, t: 327, total: 437\n",
      "1 - v: 109, t: 328, total: 437\n",
      "2 - v: 109, t: 328, total: 437\n",
      "3 - v: 109, t: 328, total: 437\n",
      "0 - v: 53, t: 157, total: 210\n",
      "1 - v: 53, t: 157, total: 210\n",
      "2 - v: 52, t: 158, total: 210\n",
      "3 - v: 52, t: 158, total: 210\n",
      "0 - v: 34, t: 99, total: 133\n",
      "1 - v: 33, t: 100, total: 133\n",
      "2 - v: 33, t: 100, total: 133\n",
      "3 - v: 33, t: 100, total: 133\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"Dataset (BUSI_with_GT) description: \n",
    "benign          (437 samples)\n",
    "malignant       (210 samples)\n",
    "normal          (133 samples)\n",
    "splits\n",
    "    benign\n",
    "        v5      0/train.txt or 0/val.txt\n",
    "    malignant\n",
    "        v5      0/train.txt or 0/val.txt\n",
    "    normal\n",
    "        v5      0/train.txt or 0/val.txt\n",
    "\"\"\"\n",
    "\n",
    "def tts(idx, test_size):\n",
    "    return train_test_split(idx, test_size=test_size)\n",
    "\n",
    "L = {\n",
    "    'benign' : 437,\n",
    "    'malignant' : 210,\n",
    "    'normal' : 133\n",
    "}\n",
    "K = 4\n",
    "\n",
    "for r, LEN in L.items():\n",
    "    val = []\n",
    "    idx = np.array([i + 1 for i in range(LEN)])\n",
    "    for k in range(K - 1):\n",
    "        idx, v = tts(idx, 1 / (K - k))\n",
    "        val.append(v)\n",
    "    val.append(idx)\n",
    "\n",
    "    idx = np.array([i + 1 for i in range(LEN)])\n",
    "    for i in range(K):\n",
    "        v = val[i].tolist()\n",
    "        t = list(set(idx.tolist()) - set(v))\n",
    "        print(f'{i} - v: {len(v)}, t: {len(t)}, total: {len(v) + len(t)}')\n",
    "        if len(list(set(v) & set(t))) > 0:\n",
    "            raise Exception\n",
    "        if not os.path.exists(f'/home/dongik/datasets/BUSI_with_GT/splits/{r}/v{K}/{i}'):\n",
    "            os.makedirs(f'/home/dongik/datasets/BUSI_with_GT/splits/{r}/v{K}/{i}')\n",
    "        with open(f'/home/dongik/datasets/BUSI_with_GT/splits/{r}/v{K}/{i}/val.txt', 'w') as f:\n",
    "            f.write('\\n'.join(str(l) for l in v))\n",
    "        with open(f'/home/dongik/datasets/BUSI_with_GT/splits/{r}/v{K}/{i}/train.txt', 'w') as f:\n",
    "            f.write('\\n'.join(str(l) for l in t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('CPNKDv5': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0812c76dadd0be11b5c2abec8e23f22451ffb3fa8606d420ca07b107c675cf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
